{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "syntaxnet\n",
    "\n",
    "bayes classifier - baseline\n",
    "\n",
    "fastext - wo lemmatization\n",
    "\n",
    "syntax data\n",
    "\n",
    "Словарь окрашенной лексики senti.ru (Лукашевич Наталья)\n",
    "\n",
    "Можно оставить только окрашенные слова либо учесть как слой\n",
    "\n",
    "Количество положительных, количество отрицательных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is availiable\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print('cuda is availiable')\n",
    "else:\n",
    "    print('cuda not availiable')\n",
    "import gensim\n",
    "\n",
    "from tqdm import tqdm_notebook, trange\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "!sudo pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    if shuffle: \n",
    "        indices = np.random.permutation(len(inputs))\n",
    "    for start_idx in trange(0, len(inputs) + 1, batchsize):\n",
    "        #print(start_idx)\n",
    "        #print(start_idx + batchsize)\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем iterate_minibatches. Готовая функция из семинаров немного косячила (не выдавала последнюю часть размера input_len % batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 3289.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((95, 5), (95,))\n",
      "((16, 5), (16,))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "XX = np.random.normal(size=(111, 5))\n",
    "YY = np.random.normal(size=111)\n",
    "for x_batch, y_batch in iterate_minibatches(XX, YY, 95):\n",
    "    print(x_batch.shape, y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py:2714: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>score</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>text_normalized</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>foursquare</td>\n",
       "      <td>2 рабочих места, выделенное рабочее место по к...</td>\n",
       "      <td>рабочий место выделять рабочий место кредит касса</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>foursquare</td>\n",
       "      <td>pos-терминал, сенсорный экран для управления \"...</td>\n",
       "      <td>pos терминал сенсорный экран для управление сб...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>foursquare</td>\n",
       "      <td>очереди имеются.</td>\n",
       "      <td>очередь иметься</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>foursquare</td>\n",
       "      <td>free wi-fi \"tattelecom_unlim\" :) good while wa...</td>\n",
       "      <td>free wi fi tattelecom good while waiting</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>foursquare</td>\n",
       "      <td>so pretty interior though</td>\n",
       "      <td>so pretty interior though</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  score      source  \\\n",
       "0           0      5  foursquare   \n",
       "1           1      5  foursquare   \n",
       "2           2      5  foursquare   \n",
       "3           3      5  foursquare   \n",
       "4           4      5  foursquare   \n",
       "\n",
       "                                                text  \\\n",
       "0  2 рабочих места, выделенное рабочее место по к...   \n",
       "1  pos-терминал, сенсорный экран для управления \"...   \n",
       "2                                   очереди имеются.   \n",
       "3  free wi-fi \"tattelecom_unlim\" :) good while wa...   \n",
       "4                          so pretty interior though   \n",
       "\n",
       "                                     text_normalized  len  \n",
       "0  рабочий место выделять рабочий место кредит касса    7  \n",
       "1  pos терминал сенсорный экран для управление сб...   12  \n",
       "2                                    очередь иметься    2  \n",
       "3           free wi fi tattelecom good while waiting    7  \n",
       "4                          so pretty interior though    4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/data/Coursework/all_data_normalized.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append('/Users/ak/Yandex.Disk.localized/sentiment-neural_past_from_Denis_Kirjanov/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#root_path = '/Users/ak/Yandex.Disk.localized/Магистратура ВШЭ/Chat_word_autofill/'\n",
    "root_path = '/data/Coursework/'\n",
    "embedding_model = gensim.models.Word2Vec\n",
    "embedding_model = embedding_model.load(root_path + 'model_normalized_with_chats_2.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уберем строки, в которых после нормализации нет ни одного слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['len'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    262789\n",
       "5    124411\n",
       "3    116753\n",
       "2     52459\n",
       "4     18975\n",
       "0         3\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.score.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уберем из данных тексты с промежуточными оценками. Можно было бы и распределить по оставшимся, но это неоднозначное решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.score.isin([1, 3, 5])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    262789\n",
       "5    124411\n",
       "3    116753\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True, subset=['text_normalized'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для удобства работы сортируем датафрейм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(by=['len'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заменим метки классов на 0,1,2. Иначе нужно танцевать с бубном, чтобы Pytorch правильно нашел метки и количество классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {1:0, 3:1, 5:2}\n",
    "data.score = data.score.replace(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>score</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>text_normalized</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>207793</th>\n",
       "      <td>207793</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>меховые тренды 2016 скачать фильм волк одиноч...</td>\n",
       "      <td>меховой тренд скачать фильм волк одиночка чере...</td>\n",
       "      <td>619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214877</th>\n",
       "      <td>214877</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>земфира волк одиночка картинки на аву для пац...</td>\n",
       "      <td>земфира волк одиночка картинка ава для пацан г...</td>\n",
       "      <td>615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210065</th>\n",
       "      <td>210065</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>утро прикол оригинальный подарок парню 14 рус...</td>\n",
       "      <td>утро прикол оригинальный подарок парень русско...</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209792</th>\n",
       "      <td>209792</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>приколы банкой парень продает подарки от деву...</td>\n",
       "      <td>прикол банка парень продавать подарок девушка ...</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210314</th>\n",
       "      <td>210314</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>приколы 18 плюс откровенно тренды детской мод...</td>\n",
       "      <td>прикол плюс откровенно тренд детский мода паца...</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  score source  \\\n",
       "207793      207793      1    NaN   \n",
       "214877      214877      1    NaN   \n",
       "210065      210065      1    NaN   \n",
       "209792      209792      1    NaN   \n",
       "210314      210314      1    NaN   \n",
       "\n",
       "                                                     text  \\\n",
       "207793   меховые тренды 2016 скачать фильм волк одиноч...   \n",
       "214877   земфира волк одиночка картинки на аву для пац...   \n",
       "210065   утро прикол оригинальный подарок парню 14 рус...   \n",
       "209792   приколы банкой парень продает подарки от деву...   \n",
       "210314   приколы 18 плюс откровенно тренды детской мод...   \n",
       "\n",
       "                                          text_normalized  len  \n",
       "207793  меховой тренд скачать фильм волк одиночка чере...  619  \n",
       "214877  земфира волк одиночка картинка ава для пацан г...  615  \n",
       "210065  утро прикол оригинальный подарок парень русско...  611  \n",
       "209792  прикол банка парень продавать подарок девушка ...  611  \n",
       "210314  прикол плюс откровенно тренд детский мода паца...  611  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собственно модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers, cell='rnn'):\n",
    "        super(SentimentRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.cell = cell\n",
    "        cell = cell.lower()\n",
    "        if cell == \"rnn\":\n",
    "            self.rnn = nn.RNN(input_size, hidden_size, n_layers)\n",
    "        elif cell == 'lstm':\n",
    "            self.rnn = nn.LSTM(input_size, hidden_size, n_layers)\n",
    "        elif cell == 'gru':\n",
    "            self.rnn = nn.GRU(input_size, hidden_size, n_layers)\n",
    "        else:\n",
    "            raise ValueError('Тип ячейки должен быть lstm, gru или rnn')\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "        self.output_size = output_size\n",
    "        self.grad_ih = None\n",
    "        self.grad_hh = None\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        # print(type(input.data), type(hidden.data))\n",
    "        #print('input shape:', input.shape, '  hidden shape:', hidden.shape)\n",
    "        print(type(input.data), type(hidden.data))\n",
    "        output, hidden = self.rnn(input, hidden)\n",
    "        #res = self.decoder(output)\n",
    "        #return res.view(-1, self.output_size), hidden\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size))\n",
    "        if torch.cuda.is_available():\n",
    "            hidden = hidden.cuda()\n",
    "        if self.cell == \"lstm\":\n",
    "            c0 = Variable(torch.randn(self.n_layers, batch_size, self.hidden_size))\n",
    "            if torch.cuda.is_available():\n",
    "                c0 = c0.cuda()\n",
    "            return (hidden, c0)\n",
    "        return hidden\n",
    "    \n",
    "    # Метод для поиска l2-норм градиентов\n",
    "    # Веса каждого слоя хранятся в своём атрибуте, для извлечения в цикле нужен getattr\n",
    "    def get_grad_norms(self):\n",
    "        grads_ih = np.zeros(self.n_layers)\n",
    "        grads_hh = np.zeros(self.n_layers)\n",
    "        for i in range(self.n_layers):\n",
    "            weight_ih = getattr(self.rnn, 'weight_ih_l'+str(i))\n",
    "            ih_norm = torch.norm(weight_ih.grad.view(-1, 1), p=2, dim=0).data.numpy()[0]\n",
    "            grads_ih[i] = ih_norm\n",
    "            \n",
    "            weight_hh = getattr(self.rnn, 'weight_hh_l'+str(i))\n",
    "            grads_hh[i] = torch.norm(weight_hh.grad.view(-1, 1), p=2, dim=0).data.numpy()[0]\n",
    "        return grads_ih, grads_hh\n",
    "    \n",
    "    def predict_proba(self, x, hidden):\n",
    "        out, _ = self.forward(x, hidden)\n",
    "        probas = F.softmax(out, dim=1)\n",
    "        return probas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, преобразующая список предложений в вектора word2vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(sentences, embedder):\n",
    "    l = len(sentences[0].split())\n",
    "    n = embedder.wv.vector_size\n",
    "    bs = len(sentences)\n",
    "    res = np.zeros([l, bs, n])\n",
    "    # Вектор для неизвестных классификатору слов\n",
    "    unknown = np.ones(embedding_size).astype('float32') * 7\n",
    "    for i in range(bs):\n",
    "        words = sentences[i].split()\n",
    "        for j in range(l):\n",
    "            try:\n",
    "                res[j, i, :] = embedder.wv[words[j]]\n",
    "            except KeyError:\n",
    "                res[j, i, :] = unknown\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку разобраться с pack_padded_sequences пока не удалось, то будем подавать батчи из предложений одинаковой длины. Значения длины перебираем в случайном порядке (иначе мб циклическое изменение функции потерь вместо уменьшения)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, inputs, targets):\n",
    "    loss_log = []\n",
    "    model.train()\n",
    "    #print('batch_size: ', batch_size)\n",
    "    for X, y in iterate_minibatches(inputs, targets, batch_size, shuffle=True):\n",
    "        t_start = datetime.now()\n",
    "        x_batch = embed(X, embedding_model)\n",
    "        #print(np.unique(y))\n",
    "        #print('Time to embed:', datetime.now() - t_start)\n",
    "        t_start = datetime.now()\n",
    "        print('batch')\n",
    "        if use_gpu:\n",
    "            x_batch = Variable(torch.from_numpy(x_batch).cuda())\n",
    "            y_batch = Variable(torch.from_numpy(y).cuda())\n",
    "        else:\n",
    "            x_batch = Variable(torch.from_numpy(x_batch).type(torch.FloatTensor))\n",
    "            y_batch = Variable(torch.from_numpy(y))\n",
    "        print(type(x_batch))\n",
    "        #print('Time to make variables:', datetime.now() - t_start)\n",
    "        #print('batch shape:', x_batch.shape)\n",
    "        hidden = model.init_hidden(x_batch.size(1))\n",
    "        #print('hidden shape:', hidden.shape, '  x shape:', x_batch.shape, '  y shape:', y_batch.shape)\n",
    "        optimizer.zero_grad()\n",
    "        loss = 0.0\n",
    "        t_start = datetime.now()\n",
    "        for i in range(x_batch.size(0)):\n",
    "            print('seq')\n",
    "            out, hidden = model.forward(x_batch[i, ...].view(1, x_batch.size(1), x_batch.size(2)), hidden)\n",
    "            #print(out.shape, hidden.shape)\n",
    "        res = model.decoder(out)\n",
    "        \n",
    "        loss = F.cross_entropy(res.view(-1, model.output_size), y_batch)\n",
    "        #out, hidden = model.forward(x_batch, hidden)\n",
    "        \n",
    "        #print(out.shape, hidden.shape, y_batch.shape)\n",
    "        # loss += F.cross_entropy(out, y_batch)\n",
    "        #print('Time to forward propagation:', datetime.now() - t_start)\n",
    "        t_start = datetime.now()\n",
    "        loss.backward()\n",
    "        #print('Time to backprop:', datetime.now() - t_start)\n",
    "        t_start = datetime.now()\n",
    "        optimizer.step()\n",
    "        #print('Time to optimizer step:', datetime.now() - t_start)\n",
    "        loss = loss.data[0]\n",
    "        loss_log.append(loss)\n",
    "    return loss_log   \n",
    "\n",
    "def test(model, inputs, targets):\n",
    "    loss_log = []\n",
    "    model.eval()\n",
    "    for X, y in iterate_minibatches(inputs, targets, batch_size):\n",
    "        x_batch = embed(X, embedding_model)\n",
    "        if use_gpu:\n",
    "            x_batch = Variable(torch.from_numpy(x_batch).cuda(0))\n",
    "            y_batch = Variable(torch.from_numpy(y).cuda(0))\n",
    "        else:\n",
    "            x_batch = Variable(torch.from_numpy(x_batch).type(torch.FloatTensor))\n",
    "            y_batch = Variable(torch.from_numpy(y))\n",
    "        hidden = model.init_hidden(x_batch.size(1))\n",
    "        loss = 0.0\n",
    "        for i in range(x_batch.size(0)):\n",
    "            out, hidden = model.forward(x_batch[i, ...].view(1, x_batch.size(1), x_batch.size(2)), hidden)\n",
    "        res = model.decoder(out)\n",
    "        loss = F.cross_entropy(res.view(-1, model.output_size), y_batch)\n",
    "        #out, hidden = model.forward(x_batch, hidden)\n",
    "        #loss += F.cross_entropy(out, y_batch)\n",
    "        loss = loss.data[0]\n",
    "        loss_log.append(loss)\n",
    "    return loss_log\n",
    "\n",
    "def plot_history(train_history, val_history, title='loss'):\n",
    "    plt.figure()\n",
    "    plt.title('{}'.format(title))\n",
    "    plt.plot(train_history, label='train', zorder=1)    \n",
    "    points = np.array(val_history)\n",
    "\n",
    "    plt.scatter(points[:, 0], points[:, 1], marker='+', s=180, c='orange', label='val', zorder=2)\n",
    "\n",
    "    plt.xlabel('train steps')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "def train(model, opt, n_epochs):\n",
    "    unique_lengths = np.unique([min(x, max_length) for x in data['len'].unique()])\n",
    "    #lengths = data['len'].values\n",
    "    # Индексы, в которых появляются новые длины\n",
    "    #change_indices = np.where(np.diff(lengths) < 0)[0] + 1\n",
    "    \n",
    "    train_log = []\n",
    "    val_log = []\n",
    "    steps = 0\n",
    "    # Сюда будем писать нормы градиентов\n",
    "    grads_ih = np.zeros([len(unique_lengths) * n_epochs, model.n_layers])\n",
    "    #print(grads_ih.shape)\n",
    "    grads_hh = np.zeros([len(unique_lengths) * n_epochs, model.n_layers])\n",
    "    for epoch in range(n_epochs):\n",
    "        for i, ul in enumerate(np.random.permutation(unique_lengths)):\n",
    "            data_cur = data[data['len'] == ul]\n",
    "            print('Length:', ul)\n",
    "            X = data_cur.text_normalized.values\n",
    "            y = data_cur.score.values\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=234769)\n",
    "            #print('data shape:', X_train.shape, X_test.shape)\n",
    "            steps += X_train.shape[0] / batch_size\n",
    "            train_loss = train_epoch(model, opt, X_train, y_train)\n",
    "            train_log.extend(train_loss)\n",
    "\n",
    "            val_loss = test(model, X_test, y_test)\n",
    "            val_log.append((steps, np.mean(val_loss)))\n",
    "            clear_output()\n",
    "            plot_history(train_log, val_log)\n",
    "            #Собственно получение градиентов\n",
    "            grad_ih, grad_hh = model.get_grad_norms()\n",
    "            grads_ih[i * (epoch + 1), :] = grad_ih\n",
    "            grads_hh[i * (epoch + 1), :] = grad_hh\n",
    "    model.grad_ih = grads_ih\n",
    "    model.grad_hh = grads_hh\n",
    "    return train_log, val_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбираем максимальную длину предложения. Критерий - должны быть учтены 99% предложений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = int(np.percentile(data['len'], 99))\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1L"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backend.cudnn.enabled=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/23 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Length:', 7)\n",
      "batch\n",
      "<class 'torch.autograd.variable.Variable'>\n",
      "seq\n",
      "(<class 'torch.cuda.DoubleTensor'>, <class 'torch.cuda.FloatTensor'>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception KeyError: KeyError(<weakref at 0x7f854cef2890; to 'tqdm' at 0x7f854ced0e90>,) in <bound method tqdm.__del__ of   0%|          | 0/23 [00:00<?, ?it/s]> ignored\n"
     ]
    },
    {
     "ename": "CuDNNError",
     "evalue": "8: CUDNN_STATUS_EXECUTION_FAILED",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCuDNNError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-53106af2a364>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu\"n_layers = 1\\nbatch_size = 1024\\nhidden_size = 250\\noutput_size = 3\\nembedding_size = embedding_model.wv.vector_size\\nn_epochs = 1\\nver = 5\\n\\nmodel = SentimentRNN(embedding_size, hidden_size, output_size, n_layers, cell='rnn')\\n#sd = torch.load('sentiment_clf_4.pth')\\n#model.load_state_dict(sd)\\nif use_gpu:\\n    model = model.cuda()\\n\\nopt = torch.optim.Adam(model.parameters(), lr=1e-4)\\ntrain_log, val_log = train(model, opt, n_epochs)\\ntorch.save(model.state_dict(), 'sentiment_clf_%i.pth'%ver)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-3cf5c3cd7ab0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, opt, n_epochs)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;31m#print('data shape:', X_train.shape, X_test.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0msteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0mtrain_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-3cf5c3cd7ab0>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, inputs, targets)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'seq'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;31m#print(out.shape, hidden.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-60a429fa6ee2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#print('input shape:', input.shape, '  hidden shape:', hidden.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;31m#res = self.decoder(output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#return res.view(-1, self.output_size), hidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/rnn.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         )\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/_functions/rnn.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutogradRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/function.pyc\u001b[0m in \u001b[0;36m_do_forward\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mflat_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_iter_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mflat_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNestedIOFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflat_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0mnested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mnested_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/function.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mnested_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_map_variable_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_extended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/_functions/rnn.pyc\u001b[0m in \u001b[0;36mforward_extended\u001b[0;34m(self, input, weight, hx)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mhy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/backends/cudnn/rnn.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(fn, input, hx, weight, output, hy)\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcy_desc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreserve\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreserve\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m             ))\n\u001b[1;32m    307\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/backends/cudnn/__init__.pyc\u001b[0m in \u001b[0;36mcheck_error\u001b[0;34m(status)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mCuDNNError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCuDNNError\u001b[0m: 8: CUDNN_STATUS_EXECUTION_FAILED"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_layers = 1\n",
    "batch_size = 1024\n",
    "hidden_size = 250\n",
    "output_size = 3\n",
    "embedding_size = embedding_model.wv.vector_size\n",
    "n_epochs = 1\n",
    "ver = 5\n",
    "\n",
    "model = SentimentRNN(embedding_size, hidden_size, output_size, n_layers, cell='rnn')\n",
    "#sd = torch.load('sentiment_clf_4.pth')\n",
    "#model.load_state_dict(sd)\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "train_log, val_log = train(model, opt, n_epochs)\n",
    "torch.save(model.state_dict(), 'sentiment_clf_%i.pth'%ver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6021"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.cudnn.version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "6021\n"
     ]
    }
   ],
   "source": [
    "print(torch.backends.cudnn.is_acceptable(torch.cuda.FloatTensor(1)))\n",
    "print(torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['len'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "21375 % batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отрисовка градиентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "legend_g = [str(i + 1) for i in range(model.n_layers)]\n",
    "# absc = np.array(range(1, n_epochs + 1)) * steps\n",
    "steps = 0.67 * len(data) / batch_size\n",
    "absc = np.array([xx[0] for xx in val_log]) \n",
    "\n",
    "plt.figure()\n",
    "plt.grid()\n",
    "plt.title('Gradient norm input to hidden vs train steps')\n",
    "for i in range(model.n_layers):\n",
    "    plt.plot(absc, model.grad_ih[:, i])\n",
    "plt.legend(legend_g)\n",
    "plt.xlabel('train steps')\n",
    "plt.gca().set_yscale('log')\n",
    "\n",
    "plt.figure()\n",
    "plt.grid()\n",
    "plt.title('Gradient norm hidden to hidden vs train steps')\n",
    "for i in range(model.n_layers):\n",
    "    plt.plot(absc, model.grad_hh[:, i])\n",
    "plt.legend(legend_g)\n",
    "plt.xlabel('train steps')\n",
    "plt.gca().set_yscale('log')\n",
    "\n",
    "\n",
    "absc = np.arange(0, model.n_layers, 1) + 1\n",
    "legend_g = [str(i + 1) for i in range(n_epochs)]\n",
    "plt.figure()\n",
    "plt.grid()\n",
    "plt.title('Gradient norm input to hidden vs layer num')\n",
    "for i in range(n_epochs):\n",
    "    plt.plot(absc, model.grad_ih[i, :])\n",
    "plt.legend(legend_g)\n",
    "plt.xlabel('layer num')\n",
    "plt.gca().set_yscale('log')\n",
    "\n",
    "plt.figure()\n",
    "plt.grid()\n",
    "plt.title('Gradient norm hidden to hidden vs layer num')\n",
    "for i in range(n_epochs):\n",
    "    plt.plot(absc, model.grad_hh[i, :])\n",
    "plt.legend(legend_g)\n",
    "plt.xlabel('layer num')\n",
    "plt.gca().set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.grad_ih.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr 20 18:49:09 2018       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 390.25                 Driver Version: 390.25                    |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  TITAN X (Pascal)    Off  | 00000000:01:00.0 Off |                  N/A |\r\n",
      "| 71%   87C    P2   171W / 250W |  11822MiB / 12194MiB |     86%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  TITAN X (Pascal)    Off  | 00000000:02:00.0 Off |                  N/A |\r\n",
      "| 61%   86C    P2   172W / 250W |  11760MiB / 12196MiB |     86%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0     22417      C   /home/dsman/anaconda3/bin/python             593MiB |\r\n",
      "|    0     24926      C   /usr/bin/python3                           10495MiB |\r\n",
      "|    0     24970      C   /home/dsman/anaconda3/bin/python             709MiB |\r\n",
      "|    1     22062      C   /usr/bin/python3                           11733MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['rnn.weight_ih_l0', 'rnn.weight_hh_l0', 'rnn.bias_ih_l0', 'rnn.bias_hh_l0', 'rnn.weight_ih_l1', 'rnn.weight_hh_l1', 'rnn.bias_ih_l1', 'rnn.bias_hh_l1', 'decoder.weight', 'decoder.bias'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
