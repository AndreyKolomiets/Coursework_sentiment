{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "use_gpu = torch.cuda.is_available()\n",
    "import gensim\n",
    "\n",
    "from tqdm import tqdm_notebook, trange\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    if shuffle: \n",
    "        indices = np.random.permutation(len(inputs))\n",
    "    for start_idx in trange(0, len(inputs) + 1, batchsize):\n",
    "        #print(start_idx)\n",
    "        #print(start_idx + batchsize)\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем iterate_minibatches. Готовая функция из семинаров немного косячила (не выдавала последнюю часть размера input_len % batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 9998.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95, 5) (95,)\n",
      "(16, 5) (16,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "XX = np.random.normal(size=(111, 5))\n",
    "YY = np.random.normal(size=111)\n",
    "for x_batch, y_batch in iterate_minibatches(XX, YY, 95):\n",
    "    print(x_batch.shape, y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ak/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>score</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>text_normalized</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>foursquare</td>\n",
       "      <td>2 рабочих места, выделенное рабочее место по к...</td>\n",
       "      <td>рабочий место выделять рабочий место кредит касса</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>foursquare</td>\n",
       "      <td>pos-терминал, сенсорный экран для управления \"...</td>\n",
       "      <td>pos терминал сенсорный экран для управление сб...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>foursquare</td>\n",
       "      <td>очереди имеются.</td>\n",
       "      <td>очередь иметься</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>foursquare</td>\n",
       "      <td>free wi-fi \"tattelecom_unlim\" :) good while wa...</td>\n",
       "      <td>free wi fi tattelecom good while waiting</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>foursquare</td>\n",
       "      <td>so pretty interior though</td>\n",
       "      <td>so pretty interior though</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  score      source  \\\n",
       "0           0      5  foursquare   \n",
       "1           1      5  foursquare   \n",
       "2           2      5  foursquare   \n",
       "3           3      5  foursquare   \n",
       "4           4      5  foursquare   \n",
       "\n",
       "                                                text  \\\n",
       "0  2 рабочих места, выделенное рабочее место по к...   \n",
       "1  pos-терминал, сенсорный экран для управления \"...   \n",
       "2                                   очереди имеются.   \n",
       "3  free wi-fi \"tattelecom_unlim\" :) good while wa...   \n",
       "4                          so pretty interior though   \n",
       "\n",
       "                                     text_normalized  len  \n",
       "0  рабочий место выделять рабочий место кредит касса    7  \n",
       "1  pos терминал сенсорный экран для управление сб...   12  \n",
       "2                                    очередь иметься    2  \n",
       "3           free wi fi tattelecom good while waiting    7  \n",
       "4                          so pretty interior though    4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('all_data_normalized.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/ak/Yandex.Disk.localized/sentiment-neural_past_from_Denis_Kirjanov/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/Users/ak/Yandex.Disk.localized/Магистратура ВШЭ/Chat_word_autofill/'\n",
    "embedding_model = gensim.models.Word2Vec\n",
    "embedding_model = embedding_model.load(root_path + 'model_normalized_with_chats_2.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['len'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    262789\n",
       "5    124411\n",
       "3    116753\n",
       "2     52459\n",
       "4     18975\n",
       "0         3\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.score.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уберем из данных тексты с промежуточными оценками. Можно было бы и распределить по оставшимся, но это неоднозначное решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.score.isin([1, 3, 5])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    262789\n",
       "5    124411\n",
       "3    116753\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True, subset=['text_normalized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(by=['len'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполняем представления. Максимальную длину предложения выбираем таким образом, чтобы 99% предложений попали полностью. Остальные обрезаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93e44787b5f4041b9303d68aa5c9067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Неизвестных слов: 23389\n"
     ]
    }
   ],
   "source": [
    "CUTOFF = int(1e4)\n",
    "lengths = data['len'].values[:CUTOFF]\n",
    "\n",
    "max_length = int(np.percentile(data['len'], 99))\n",
    "embedding_size = embedding_model.wv.vector_size\n",
    "unknown = np.ones(embedding_size).astype('float32') * 7\n",
    "num_unknown = 0\n",
    "embeddings = np.zeros([CUTOFF, max_length, embedding_size])\n",
    "i = 0\n",
    "for text in tqdm_notebook(data.text_normalized.values[:CUTOFF]):\n",
    "    #emb = np.zeros([embedding_size, max_length]).astype('float32')\n",
    "    words = text.split()\n",
    "    if lengths[i] > max_length:\n",
    "        lengths[i] = max_length\n",
    "    for j in range(min(len(words), max_length)):\n",
    "        try:\n",
    "            #emb[:, i] = embedding_model.wv[words[i]]#.astype('float32')\n",
    "            embeddings[i, j, :] = embedding_model.wv[words[j]]\n",
    "        except KeyError:\n",
    "            embeddings[i, j, :] = unknown\n",
    "            num_unknown += 1\n",
    "            #print(words[i])\n",
    "    i += 1\n",
    "print('Неизвестных слов:', num_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = data.score.values[:CUTOFF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed = pack_padded_sequence(Variable(torch.from_numpy(embeddings)), lengths, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=Variable containing:\n",
       " 7.0000e+00  7.0000e+00  7.0000e+00  ...   7.0000e+00  7.0000e+00  7.0000e+00\n",
       " 7.0000e+00  7.0000e+00  7.0000e+00  ...   7.0000e+00  7.0000e+00  7.0000e+00\n",
       " 1.7459e-01 -1.2062e+00  3.0000e-01  ...  -1.0233e+00  5.0580e-01 -9.9476e-01\n",
       "                ...                   ⋱                   ...                \n",
       "-1.0303e+00 -4.5521e-01 -1.0325e+00  ...  -1.1374e+00 -3.6873e-02 -1.8809e+00\n",
       "-3.4304e-02 -2.2295e-02  6.7112e-01  ...   2.7297e-01 -2.8302e-01  1.4054e+00\n",
       " 4.7893e-01 -2.8866e+00  6.3675e-01  ...   6.6361e-01 -3.3833e-01 -9.0275e-01\n",
       "[torch.DoubleTensor of size 302672x300]\n",
       ", batch_sizes=[10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 9818, 8499, 7436, 6433, 5576, 4910])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, (10000, 32, 300), 32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lengths), embeddings.shape, max(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "lengths array has incorrect size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-66c32d004f3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mxx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpack_padded_sequence\u001b[0;34m(input, lengths, batch_first)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lengths array has incorrect size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mprev_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: lengths array has incorrect size"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([[12,13,14,15], [2,6,9,3], [2,3,0,0], [1,4,0,0]])\n",
    "xx = pack_padded_sequence(a, [4, 2], batch_first=False)\n",
    "xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно разобраться с pack_padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[9.19344174e+02 2.74072352e+01 6.38354858e-02]\n",
      "  [1.10168698e+03 7.24852318e-01 9.56330245e-01]\n",
      "  [9.75431071e+02 2.64327000e+01 0.00000000e+00]\n",
      "  [1.10624397e+03 0.00000000e+00 0.00000000e+00]\n",
      "  [1.06370142e+03 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[1.11646582e+03 3.51659927e+00 9.01379721e-01]\n",
      "  [9.18423441e+02 4.60765079e+01 1.00025268e-01]\n",
      "  [8.67228755e+02 2.25143125e+01 0.00000000e+00]\n",
      "  [1.08703853e+03 0.00000000e+00 0.00000000e+00]\n",
      "  [1.05876788e+03 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[1.05934238e+03 3.04389368e+00 1.41118283e-01]\n",
      "  [8.01125879e+02 3.99937466e+01 6.96427843e-01]\n",
      "  [1.04267375e+03 3.62776941e+01 0.00000000e+00]\n",
      "  [8.70328594e+02 0.00000000e+00 0.00000000e+00]\n",
      "  [9.08048982e+02 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[1.04314573e+03 2.11993418e+01 6.43678521e-01]\n",
      "  [9.82347960e+02 1.96481519e+01 7.49106319e-02]\n",
      "  [1.03636169e+03 1.17672199e+00 0.00000000e+00]\n",
      "  [1.05779951e+03 0.00000000e+00 0.00000000e+00]\n",
      "  [1.17490803e+03 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[1.14698046e+03 2.03066599e+01 4.43683268e-01]\n",
      "  [9.66504631e+02 3.87299610e+01 4.46421569e-01]\n",
      "  [1.03438071e+03 1.17405857e+01 0.00000000e+00]\n",
      "  [7.84968505e+02 0.00000000e+00 0.00000000e+00]\n",
      "  [1.01508377e+03 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[9.28934865e+02 3.90860520e+01 3.02822889e-01]\n",
      "  [9.82720698e+02 4.24837894e+01 8.15190403e-01]\n",
      "  [1.05825234e+03 2.23456854e+01 0.00000000e+00]\n",
      "  [9.54975246e+02 0.00000000e+00 0.00000000e+00]\n",
      "  [1.16700099e+03 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[1.04046285e+03 2.36882714e+01 8.52355185e-01]\n",
      "  [1.26955698e+03 3.90453173e+01 8.04244354e-01]\n",
      "  [9.56640720e+02 4.07115653e+01 0.00000000e+00]\n",
      "  [9.85111737e+02 0.00000000e+00 0.00000000e+00]\n",
      "  [1.01906006e+03 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[9.04870170e+02 3.17558611e+01 8.53435157e-01]\n",
      "  [1.04828330e+03 2.92852541e+01 7.86765829e-01]\n",
      "  [9.17244802e+02 2.15864031e+01 0.00000000e+00]\n",
      "  [1.01302847e+03 0.00000000e+00 0.00000000e+00]\n",
      "  [1.06034379e+03 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[9.95224321e+02 2.54495740e+01 6.29585713e-01]\n",
      "  [9.84115489e+02 3.78718799e+01 8.94482362e-01]\n",
      "  [1.07822762e+03 1.50216042e+00 0.00000000e+00]\n",
      "  [7.77204301e+02 0.00000000e+00 0.00000000e+00]\n",
      "  [9.14506463e+02 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[1.09834707e+03 1.66132627e+01 8.28501329e-01]\n",
      "  [1.03221012e+03 2.15912298e+01 6.78276930e-01]\n",
      "  [1.06261795e+03 1.23350167e+01 0.00000000e+00]\n",
      "  [8.93742250e+02 0.00000000e+00 0.00000000e+00]\n",
      "  [1.07862895e+03 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[1.14568825e+03 2.55400420e+01 7.49753906e-01]\n",
      "  [8.00301919e+02 1.27605626e+01 9.29774943e-01]\n",
      "  [1.03415593e+03 2.62130427e+01 0.00000000e+00]\n",
      "  [9.44128580e+02 0.00000000e+00 0.00000000e+00]\n",
      "  [1.15018474e+03 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      " [[1.01800078e+03 1.04946417e+01 9.46713123e-01]\n",
      "  [1.07833308e+03 1.80893423e+01 1.77291028e-02]\n",
      "  [9.73299167e+02 1.81841954e+01 0.00000000e+00]\n",
      "  [1.00637899e+03 0.00000000e+00 0.00000000e+00]\n",
      "  [1.12089011e+03 0.00000000e+00 0.00000000e+00]]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(100500)\n",
    "emb_size = 12\n",
    "vec1 = np.random.normal(size=[emb_size,5], loc=10, scale=1) * 100\n",
    "vec2 = np.hstack((np.random.uniform(size=[emb_size, 3]) * 50, np.zeros([emb_size, 2])))\n",
    "vec3 = np.hstack([np.random.uniform(size=[emb_size, 2]), np.zeros([emb_size, 3])])\n",
    "vec = np.dstack([vec1, vec2, vec3])\n",
    "print(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 5, 3)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 12])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.from_numpy(vec.transpose(1, 2, 0))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "Columns 0 to 5 \n",
       " 9.1934e+02  1.1165e+03  1.0593e+03  1.0431e+03  1.1470e+03  9.2893e+02\n",
       " 2.7407e+01  3.5166e+00  3.0439e+00  2.1199e+01  2.0307e+01  3.9086e+01\n",
       " 6.3835e-02  9.0138e-01  1.4112e-01  6.4368e-01  4.4368e-01  3.0282e-01\n",
       "\n",
       "Columns 6 to 11 \n",
       " 1.0405e+03  9.0487e+02  9.9522e+02  1.0983e+03  1.1457e+03  1.0180e+03\n",
       " 2.3688e+01  3.1756e+01  2.5450e+01  1.6613e+01  2.5540e+01  1.0495e+01\n",
       " 8.5236e-01  8.5344e-01  6.2959e-01  8.2850e-01  7.4975e-01  9.4671e-01\n",
       "[torch.DoubleTensor of size 3x12]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = pack_padded_sequence(a, [5, 3, 2], batch_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=\n",
       "\n",
       "Columns 0 to 5 \n",
       " 9.1934e+02  1.1165e+03  1.0593e+03  1.0431e+03  1.1470e+03  9.2893e+02\n",
       " 2.7407e+01  3.5166e+00  3.0439e+00  2.1199e+01  2.0307e+01  3.9086e+01\n",
       " 6.3835e-02  9.0138e-01  1.4112e-01  6.4368e-01  4.4368e-01  3.0282e-01\n",
       " 1.1017e+03  9.1842e+02  8.0113e+02  9.8235e+02  9.6650e+02  9.8272e+02\n",
       " 7.2485e-01  4.6077e+01  3.9994e+01  1.9648e+01  3.8730e+01  4.2484e+01\n",
       " 9.5633e-01  1.0003e-01  6.9643e-01  7.4911e-02  4.4642e-01  8.1519e-01\n",
       " 9.7543e+02  8.6723e+02  1.0427e+03  1.0364e+03  1.0344e+03  1.0583e+03\n",
       " 2.6433e+01  2.2514e+01  3.6278e+01  1.1767e+00  1.1741e+01  2.2346e+01\n",
       " 1.1062e+03  1.0870e+03  8.7033e+02  1.0578e+03  7.8497e+02  9.5498e+02\n",
       " 1.0637e+03  1.0588e+03  9.0805e+02  1.1749e+03  1.0151e+03  1.1670e+03\n",
       "\n",
       "Columns 6 to 11 \n",
       " 1.0405e+03  9.0487e+02  9.9522e+02  1.0983e+03  1.1457e+03  1.0180e+03\n",
       " 2.3688e+01  3.1756e+01  2.5450e+01  1.6613e+01  2.5540e+01  1.0495e+01\n",
       " 8.5236e-01  8.5344e-01  6.2959e-01  8.2850e-01  7.4975e-01  9.4671e-01\n",
       " 1.2696e+03  1.0483e+03  9.8412e+02  1.0322e+03  8.0030e+02  1.0783e+03\n",
       " 3.9045e+01  2.9285e+01  3.7872e+01  2.1591e+01  1.2761e+01  1.8089e+01\n",
       " 8.0424e-01  7.8677e-01  8.9448e-01  6.7828e-01  9.2977e-01  1.7729e-02\n",
       " 9.5664e+02  9.1724e+02  1.0782e+03  1.0626e+03  1.0342e+03  9.7330e+02\n",
       " 4.0712e+01  2.1586e+01  1.5022e+00  1.2335e+01  2.6213e+01  1.8184e+01\n",
       " 9.8511e+02  1.0130e+03  7.7720e+02  8.9374e+02  9.4413e+02  1.0064e+03\n",
       " 1.0191e+03  1.0603e+03  9.1451e+02  1.0786e+03  1.1502e+03  1.1209e+03\n",
       "[torch.DoubleTensor of size 10x12]\n",
       ", batch_sizes=[3, 3, 2, 1, 1])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers, cell='rnn'):\n",
    "        super(SentimentRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.cell = cell\n",
    "        if cell == \"rnn\":\n",
    "            self.rnn = nn.RNN(hidden_size, hidden_size, n_layers)\n",
    "        else:\n",
    "            self.rnn = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        bs = input.size(0)\n",
    "        reordered = input.view(1, bs, -1)\n",
    "        output, hidden = self.rnn(reordered, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size))\n",
    "        if self.cell == \"lstm\":\n",
    "            c0 = Variable(torch.randn(self.n_layers, batch_size, self.hidden_size))\n",
    "            return (hidden, c0)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 5\n",
    "batch_size = 256\n",
    "model = SentimentRNN(250, 3, n_layers, 'rnn')\n",
    "if use_gpu:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, преобразующая список предложений в word2vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(sentences, embedder):\n",
    "    l = len(sentences[0].split())\n",
    "    n = embedder.wv.vector_size\n",
    "    bs = len(sentences)\n",
    "    res = np.zeros([l, bs, n])\n",
    "    for i in range(bs):\n",
    "        words = sentences[i].split()\n",
    "        for j in range(l):\n",
    "            res[j, i, :] = embedder.wv[words[j]]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку разобраться с pack_padded_sequences пока не удалось, то будем подавать батчи из предложений одинаковой длины, начиная с самых длинных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, inputs, targets):\n",
    "    loss_log = []\n",
    "    model.train()\n",
    "    for X, y in iterate_minibatches(inputs, targets):\n",
    "        x_batch = embed(X, embedding_model)\n",
    "        hidden = model.init_hidden(x_batch.shape[0])\n",
    "        optimizer.zero_grad()\n",
    "        loss = 0.0\n",
    "        for i in range(0, t.shape[1] - 1):\n",
    "            out, hidden = model.forward(t[:, i], hidden)\n",
    "            loss += F.cross_entropy(out, t[:, i+1])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss = loss.data[0]\n",
    "        loss_log.append(loss)\n",
    "    return loss_log   \n",
    "\n",
    "def test(model, x_batch, y_batch):\n",
    "    loss_log = []\n",
    "    model.eval()\n",
    "    for batch in test_batches:\n",
    "        nums = to_matrix(batch)\n",
    "        t = Variable(torch.from_numpy(nums))\n",
    "        y = Variable(torch.from_numpy(nums[:,1:]))\n",
    "        x = Variable(torch.from_numpy(nums[:, :-1]))\n",
    "        hidden = model.init_hidden(x.shape[0])\n",
    "        loss = 0.0\n",
    "        for i in range(0, t.shape[1] - 1):\n",
    "            out, hidden = model.forward(t[:, i], hidden)\n",
    "            loss += F.cross_entropy(out, t[:, i+1])\n",
    "\n",
    "        loss = loss.data[0]\n",
    "        loss_log.append(loss)\n",
    "    return loss_log\n",
    "\n",
    "def plot_history(train_history, val_history, title='loss'):\n",
    "    plt.figure()\n",
    "    plt.title('{}'.format(title))\n",
    "    plt.plot(train_history, label='train', zorder=1)    \n",
    "    points = np.array(val_history)\n",
    "\n",
    "    plt.scatter(points[:, 0], points[:, 1], marker='+', s=180, c='orange', label='val', zorder=2)\n",
    "\n",
    "    plt.xlabel('train steps')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "def train(model, opt, n_epochs):\n",
    "    unique_lengths = np.unique([min(x, max_length) for x in data['len'].unique()])\n",
    "    #lengths = data['len'].values\n",
    "    # Индексы, в которых появляются новые длины\n",
    "    #change_indices = np.where(np.diff(lengths) < 0)[0] + 1\n",
    "    \n",
    "    train_log = []\n",
    "    val_log = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for ul in unique_lengths:\n",
    "            if ul >= max_length:\n",
    "                data_cur = data[data['len'] >= ul]\n",
    "            else:\n",
    "                data_cur = data[data['len'] == ul]\n",
    "            X = data_cur.text_normalized.values\n",
    "            y = data_cur.score.values\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=234769)\n",
    "            steps = X_train.shape[0] / batch_size\n",
    "                \n",
    "            train_loss = train_epoch(model, opt, X_train, y_train)\n",
    "            train_log.extend(train_loss)\n",
    "\n",
    "            val_loss = test(model, X_test, y_test)\n",
    "            val_log.append((steps * (epoch + 1), np.mean(val_loss)))\n",
    "            clear_output()\n",
    "            plot_history(train_log, val_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([3,3,3,2,2,1,1,1,1])\n",
    "np.where(np.diff(a) < 0)[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.concatenate([np.ones(16)*3, np.ones(12)*2, np.ones(8)])\n",
    "indices = [0] + list(np.where(np.diff(a) < 0)[0] + 1) + [len(a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([3., 3., 3., 3., 3., 3.]), array([3., 3., 3., 3., 3.]), array([3., 3., 3., 3., 3.])]\n",
      "[array([2., 2., 2., 2., 2., 2.]), array([2., 2., 2., 2., 2., 2.])]\n",
      "[array([1., 1., 1., 1., 1., 1., 1., 1.])]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "for i in range(len(indices) - 1):\n",
    "    print(np.array_split(a[indices[i]:indices[i + 1]], (indices[i + 1] - indices[i] + 1) // batch_size)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby, zip_longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "(3.0, 3.0, 3.0, 3.0, 3.0)\n",
      "(3.0, 3.0, 3.0, 3.0, 3.0)\n",
      "(3.0, 3.0, 3.0, 3.0, 3.0)\n",
      "(3.0, None, None, None, None)\n",
      "2.0\n",
      "(2.0, 2.0, 2.0, 2.0, 2.0)\n",
      "(2.0, 2.0, 2.0, 2.0, 2.0)\n",
      "(2.0, 2.0, None, None, None)\n",
      "1.0\n",
      "(1.0, 1.0, 1.0, 1.0, 1.0)\n",
      "(1.0, 1.0, 1.0, None, None)\n"
     ]
    }
   ],
   "source": [
    "ind = list(range(len(a)))\n",
    "for k, g in groupby(a):\n",
    "    print(k)\n",
    "    #print(list(g))\n",
    "    for x in grouper(g, 5):\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция, позволяющая в цикле перебирать подмассивы по n значений вместо отдельных элементов\n",
    "def grouper(iterable, n, fillvalue=None):\n",
    "    args = [iter(iterable)] * n\n",
    "    return zip_longest(*args, fillvalue=fillvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "train(model, opt, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([619, 615, 611, 610, 608, 604, 601, 599, 598, 595, 591, 590, 589,\n",
       "       588, 585, 583, 582, 576, 575, 574, 572, 571, 568, 563, 330, 319,\n",
       "       216, 200, 182, 181, 176, 159, 155, 151, 150, 142, 141, 136, 132,\n",
       "       130, 129, 125, 123, 122, 121, 116, 115, 114, 112, 111, 110, 108,\n",
       "       107, 105, 103, 101,  98,  97,  95,  94,  93,  92,  91,  90,  89,\n",
       "        88,  87,  86,  85,  84,  83,  82,  81,  80,  79,  78,  77,  76,\n",
       "        75,  74,  73,  72,  71,  70,  69,  68,  67,  66,  65,  64,  63,\n",
       "        62,  61,  60,  59,  58,  57,  56,  55,  54,  53,  52,  51,  50,\n",
       "        49,  48,  47,  46,  45,  44,  43,  42,  41,  40,  39,  38,  37,\n",
       "        36,  35,  34,  33,  32,  31,  30,  29,  28,  27,  26,  25,  24,\n",
       "        23,  22,  21,  20,  19,  18,  17,  16,  15,  14,  13,  12,  11,\n",
       "        10,   9,   8,   7,   6,   5,   4,   3,   2,   1])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['len'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
